const fs = require('fs-extra');
const path = require('path');
const cheerio = require('cheerio');

const { delay } = require('./utils/delay');
const { extractUserInfo } = require('./utils/urlUtils');
const { getImageName } = require('./utils/urlUtils');
const { downloadImage, savePostMetadata, saveHtmlContent, readProfilesFile } = require('./utils/fileUtils');
const { fetchPage, fetchPostsFromAPI, fetchPostFromAPI } = require('./api/kemonoApi');
const { extractImagesFromPostData, extractImagesFromHTML } = require('./extractors/imageExtractor');
const { isPostAlreadyDownloaded, getDownloadStatus, verifyAllImagesDownloaded } = require('./utils/downloadChecker');
const ConcurrentDownloader = require('./utils/concurrentDownloader');
const config = require('./utils/config');

class KemonoDownloader {
  constructor() {
    this.baseDir = config.getBaseDirectory();
    this.concurrentDownloader = new ConcurrentDownloader();
    this.stats = {
      profilesProcessed: 0,
      postsDownloaded: 0,
      postsSkipped: 0,
      imagesDownloaded: 0,
      errors: 0
    };
  }

  async initialize() {
    await config.load();
    this.baseDir = config.getBaseDirectory();
    console.log(`üìÅ Base directory: ${this.baseDir}`);
    console.log(`‚ö° Max concurrent images: ${config.getMaxConcurrentImages()}`);
    console.log(`‚è±Ô∏è  Image delay: ${config.getImageDelay()}ms`);
  }

  async getProfilePosts(profileUrl) {
    console.log(`  üîç Analyzing profile for posts...`);
    const userInfo = extractUserInfo(profileUrl);
    
    // Try API first, then fallback to HTML scraping
    console.log(`  üîå Trying API endpoint for user ${userInfo.userId}...`);
    const apiPosts = await fetchPostsFromAPI(userInfo.service, userInfo.userId, (msg) => console.log(`    ${msg}`));
    
    if (apiPosts.length > 0) {
      console.log(`  ‚úÖ Found ${apiPosts.length} posts via API`);
      return apiPosts;
    }
    
    console.log(`  ‚ö†Ô∏è  API failed, trying HTML scraping fallback...`);
    return await this.getProfilePostsFromHTML(profileUrl);
  }

  async getProfilePostsFromHTML(profileUrl) {
    const html = await fetchPage(profileUrl, (msg) => console.log(`  ${msg}`));
    if (!html) {
      console.log(`  ‚ùå Could not load profile page`);
      return [];
    }

    const $ = cheerio.load(html);
    const posts = [];
    const userInfo = extractUserInfo(profileUrl);

    // Extract username from page
    const username = $('.user-header__info span[itemprop="name"]').text().trim() || 
                    $('.user-header__profile h1').text().trim() || 
                    $('h1').first().text().trim() || 
                    `user_${userInfo.userId}`;

    console.log(`  üë§ Found user: ${username}`);

    // Check if this is a SPA (Single Page Application)
    const bodyText = $('body').text().substring(0, 500);
    if (bodyText.includes('System.import') || bodyText.includes('vite-legacy-entry')) {
      console.log(`  ‚ö†Ô∏è  Detected SPA - content loaded dynamically via JavaScript`);
      console.log(`  üí° This site requires JavaScript to load posts. Consider:`);
      console.log(`     1. Check if the user has posts (visit the URL manually)`);
      console.log(`     2. The site may have moved or changed structure`);
      console.log(`     3. API endpoints may have changed`);
      return [];
    }

    console.log(`  üîç Debug: HTML length: ${html.length} characters`);
    console.log(`  üîç Debug: All links count: ${$('a').length}`);
    
    // Try multiple selectors to find posts
    const postSelectors = [
      'article.post-card',
      '.post-card', 
      'article',
      '.card',
      '[href*="/post/"]',
      'a[href*="/post/"]'
    ];

    let postsFound = false;

    for (const selector of postSelectors) {
      const elements = $(selector);
      
      if (elements.length > 0) {
        console.log(`  üîç Found ${elements.length} elements with selector: ${selector}`);
        elements.each((index, element) => {
          const $element = $(element);
          
          // Try different ways to find post links
          let postLink = null;
          
          if ($element.is('a')) {
            postLink = $element.attr('href');
          } else {
            postLink = $element.find('a').first().attr('href') || 
                      $element.find('[href*="/post/"]').first().attr('href');
          }
          
          if (postLink && postLink.includes('/post/')) {
            const fullPostUrl = postLink.startsWith('http') ? postLink : `https://kemono.su${postLink}`;
            const postId = this.extractPostId(fullPostUrl);
            
            posts.push({
              url: fullPostUrl,
              id: postId,
              username: username.replace(/[<>:"/\\|?*]/g, '_') // Sanitize filename
            });
            postsFound = true;
          }
        });
        
        if (postsFound) {
          console.log(`  ‚úÖ Successfully found posts using selector: ${selector}`);
          break;
        }
      }
    }

    console.log(`  üìã Found ${posts.length} posts to download`);
    return posts;
  }

  extractPostId(postUrl) {
    const urlParts = postUrl.split('/');
    return urlParts[urlParts.length - 1] || 'unknown';
  }

  async downloadPost(post, postIndex, totalPosts) {
    console.log(`\nüìÑ [${postIndex + 1}/${totalPosts}] Processing post: ${post.id}`);
    console.log(`  üîó URL: ${post.url}`);
    
    const postDir = path.join(this.baseDir, post.username, post.id);
    
    // First, check if we should skip this post
    const quickCheck = await getDownloadStatus(postDir);
    if (quickCheck === 'completed') {
      // Do a quick check without API data first
      const initialCheck = await isPostAlreadyDownloaded(postDir, null);
      if (initialCheck.downloaded) {
        console.log(`  ‚è≠Ô∏è  Skipping: Post already downloaded and verified`);
        this.stats.postsSkipped++;
        return;
      }
    }
    
    console.log(`  üìÅ Creating directory: ${postDir}`);
    await fs.ensureDir(postDir);

    // Try to get post content from API first
    const postData = await fetchPostFromAPI(post, (msg) => console.log(`    ${msg}`));
    
    // If we have post data, do a thorough check including image verification
    if (postData) {
      const thoroughCheck = await isPostAlreadyDownloaded(postDir, postData);
      if (thoroughCheck.downloaded) {
        console.log(`  ‚è≠Ô∏è  Skipping: Post already fully downloaded with all ${extractImagesFromPostData(postData).length} images verified`);
        this.stats.postsSkipped++;
        return;
      } else if (thoroughCheck.missingImages && thoroughCheck.missingImages.length > 0) {
        console.log(`  üîÑ Resuming: Missing ${thoroughCheck.missingImages.length} images - ${thoroughCheck.reason}`);
      }
    }
    
    if (postData) {
      console.log(`  ‚úÖ Got post data from API`);
      
      // Save post metadata as JSON
      await savePostMetadata(postDir, postData);
      console.log(`  üíæ Saved post metadata`);
      
      // Extract and download images from API data using concurrent downloader
      const images = extractImagesFromPostData(postData);
      console.log(`  üñºÔ∏è  Found ${images.length} images to download`);
      
      if (images.length > 0) {
        const downloadStats = await this.concurrentDownloader.downloadImages(
          images,
          postDir,
          (msg) => console.log(`    ${msg}`),
          (stats) => {
            this.stats.imagesDownloaded += stats.completed;
            this.stats.errors += stats.failed;
            console.log(`  üìä Batch complete: ${stats.completed} downloaded, ${stats.skipped} skipped, ${stats.failed} failed`);
          }
        );

        // Verify all images were downloaded correctly after batch completion
        await this.verifyPostImages(postDir, images, post.id);
      }
      
    } else {
      console.log(`  ‚ö†Ô∏è  API failed, trying HTML fallback...`);
      
      const html = await fetchPage(post.url, (msg) => console.log(`  ${msg}`));
      if (!html) {
        console.log(`  ‚ùå Skipping post due to fetch failure`);
        return;
      }

      const $ = cheerio.load(html);
      
      // Save HTML content
      await saveHtmlContent(postDir, html);
      console.log(`  üíæ Saving HTML content...`);

      // Check if this is SPA content
      const bodyText = $('body').text();
      if (bodyText.includes('System.import') || bodyText.includes('vite-legacy-entry')) {
        console.log(`  ‚ö†Ô∏è  Post page is also a SPA - no images can be extracted from HTML`);
        console.log(`  üí° Content is loaded dynamically. API method needed for images.`);
      } else {
        // Try to extract images from HTML (fallback)
        const images = extractImagesFromHTML($);
        console.log(`  üñºÔ∏è  Found ${images.length} images to download`);
        
        for (let i = 0; i < images.length; i++) {
          const imageUrl = images[i];
          const imageName = getImageName(imageUrl, i);
          const imagePath = path.join(postDir, imageName);
          
          try {
            await downloadImage(imageUrl, imagePath, (msg) => console.log(`    ${msg}`));
            this.stats.imagesDownloaded++;
            // Small delay between image downloads
            await delay(200);
          } catch (error) {
            this.stats.errors++;
            console.log(`    ‚ö†Ô∏è  Continuing with next image...`);
          }
        }
      }
    }

    this.stats.postsDownloaded++;
    console.log(`  ‚úÖ Post ${post.id} completed - saved to ${postDir}`);
  }

  async processProfilesFile(filename) {
    try {
      console.log(`üìÇ Reading profiles from: ${filename}`);
      const profileUrls = await readProfilesFile(filename);

      console.log(`üìã Found ${profileUrls.length} profile URLs to process\n`);

      for (let i = 0; i < profileUrls.length; i++) {
        const profileUrl = profileUrls[i];
        console.log(`\nüîÑ [${i + 1}/${profileUrls.length}] Processing profile: ${profileUrl}`);
        
        try {
          const posts = await this.getProfilePosts(profileUrl);
          
          if (posts.length === 0) {
            console.log(`  ‚ö†Ô∏è  No posts found for this profile`);
            continue;
          }

          for (let j = 0; j < posts.length; j++) {
            await this.downloadPost(posts[j], j, posts.length);
            
            // Show progress bar after each post
            const progress = ((j + 1) / posts.length * 100).toFixed(1);
            const completedBars = Math.floor((j + 1) / posts.length * 20);
            const remainingBars = 20 - completedBars;
            const progressBar = '‚ñà'.repeat(completedBars) + '‚ñë'.repeat(remainingBars);
            console.log(`  üìä Progress: [${progressBar}] ${j + 1}/${posts.length} (${progress}%)`);
          }
          
          this.stats.profilesProcessed++;
          console.log(`  ‚úÖ Profile completed`);
        } catch (error) {
          this.stats.errors++;
          console.error(`  ‚ùå Error processing profile: ${error.message}`);
          console.log(`  ‚è≠Ô∏è  Continuing with next profile...`);
        }
      }

      this.printSummary();
    } catch (error) {
      this.stats.errors++;
      console.error(`‚ùå Error processing profiles file: ${error.message}`);
    }
  }

  async verifyPostImages(postDir, expectedImages, postId) {
    console.log(`  üîç Verifying ${expectedImages.length} images for post ${postId}...`);
    
    try {
      const verification = await verifyAllImagesDownloaded(postDir, expectedImages);
      
      if (verification.allPresent) {
        console.log(`  ‚úÖ Verification passed: All ${verification.presentCount}/${verification.totalExpected} images verified`);
      } else {
        console.log(`  ‚ö†Ô∏è  Verification issues found:`);
        console.log(`      üìä Present: ${verification.presentCount}/${verification.totalExpected}`);
        
        if (verification.missingFiles.length > 0) {
          console.log(`      ‚ùå Missing files (${verification.missingFiles.length}):`);
          verification.missingFiles.slice(0, 5).forEach(file => {
            console.log(`         ‚Ä¢ ${file}`);
          });
          if (verification.missingFiles.length > 5) {
            console.log(`         ... and ${verification.missingFiles.length - 5} more`);
          }
        }
        
        if (verification.corruptedFiles.length > 0) {
          console.log(`      üîß Corrupted files (${verification.corruptedFiles.length}):`);
          verification.corruptedFiles.slice(0, 5).forEach(file => {
            console.log(`         ‚Ä¢ ${file.name} (${file.reason})`);
          });
          if (verification.corruptedFiles.length > 5) {
            console.log(`         ... and ${verification.corruptedFiles.length - 5} more`);
          }
        }
        
        // Update stats to reflect verification issues
        this.stats.errors += verification.missingCount;
      }
    } catch (error) {
      console.log(`  ‚ùå Verification failed: ${error.message}`);
      this.stats.errors++;
    }
  }

  printSummary() {
    console.log('\n' + '='.repeat(50));
    console.log('üìä DOWNLOAD SUMMARY');
    console.log('='.repeat(50));
    console.log(`‚úÖ Profiles processed: ${this.stats.profilesProcessed}`);
    console.log(`üìÑ Posts downloaded: ${this.stats.postsDownloaded}`);
    console.log(`‚è≠Ô∏è  Posts skipped: ${this.stats.postsSkipped}`);
    console.log(`üñºÔ∏è  Images downloaded: ${this.stats.imagesDownloaded}`);
    console.log(`‚ùå Errors encountered: ${this.stats.errors}`);
    console.log('='.repeat(50));
    
    if (this.stats.errors === 0) {
      console.log('üéâ All downloads completed successfully!');
    } else {
      console.log('‚ö†Ô∏è  Some errors occurred during download. Check logs above.');
    }
  }
}

module.exports = KemonoDownloader;