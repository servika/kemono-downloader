const fs = require('fs-extra');
const path = require('path');
const cheerio = require('cheerio');

const { delay } = require('./utils/delay');
const { extractUserInfo, extractProfileName } = require('./utils/urlUtils');
const { getImageName } = require('./utils/urlUtils');
const { downloadImage, savePostMetadata, saveHtmlContent, readProfilesFile } = require('./utils/fileUtils');
const { fetchPage, fetchPostsFromAPI, fetchPostFromAPI } = require('./api/kemonoApi');
const { extractImagesFromPostData, extractImagesFromHTML } = require('./extractors/imageExtractor');
const { extractPostsFromProfileHTML, extractMediaFromPostHTML, extractPostMetadataFromHTML, extractUsernameFromProfile } = require('./extractors/htmlParser');
const { isPostAlreadyDownloaded, getDownloadStatus, verifyAllImagesDownloaded } = require('./utils/downloadChecker');
const ConcurrentDownloader = require('./utils/concurrentDownloader');
const config = require('./utils/config');
const browserClient = require('./utils/browserClient');

class KemonoDownloader {
  constructor() {
    this.baseDir = config.getBaseDirectory();
    this.concurrentDownloader = new ConcurrentDownloader();
    this.stats = {
      profilesProcessed: 0,
      postsDownloaded: 0,
      postsSkipped: 0,
      imagesDownloaded: 0,
      errors: 0
    };
  }

  async initialize() {
    await config.load();
    this.baseDir = config.getBaseDirectory();
    this.htmlOnlyMode = config.get('htmlOnlyMode', false);
    console.log(`ğŸ“ Base directory: ${this.baseDir}`);
    console.log(`âš¡ Max concurrent images: ${config.getMaxConcurrentImages()}`);
    console.log(`â±ï¸  Image delay: ${config.getImageDelay()}ms`);
    if (this.htmlOnlyMode) {
      console.log(`ğŸŒ HTML-only mode: ENABLED (API will be skipped)`);
    }
  }

  async getProfilePosts(profileUrl) {
    console.log(`  ğŸ” Analyzing profile for posts...`);
    const userInfo = extractUserInfo(profileUrl);

    // Try browser HTML scraping first
    console.log(`  ğŸŒ Trying browser HTML scraping...`);
    const htmlPosts = await this.getProfilePostsFromHTML(profileUrl);

    if (htmlPosts.length > 0) {
      console.log(`  âœ… Found ${htmlPosts.length} posts via HTML scraping`);
      return htmlPosts;
    }

    // Skip API if in HTML-only mode
    if (this.htmlOnlyMode) {
      console.log(`  âš ï¸  HTML scraping found no posts (API skipped - HTML-only mode)`);
      return [];
    }

    console.log(`  âš ï¸  HTML scraping failed, trying API fallback...`);
    console.log(`  ğŸ”Œ Trying API endpoint for user ${userInfo.userId}...`);
    const apiPosts = await fetchPostsFromAPI(userInfo.service, userInfo.userId, (msg) => console.log(`    ${msg}`));

    if (apiPosts.length > 0) {
      console.log(`  âœ… Found ${apiPosts.length} posts via API`);
    }

    return apiPosts;
  }

  async getProfilePostsFromHTML(profileUrl) {
    const html = await fetchPage(profileUrl, (msg) => console.log(`  ${msg}`));
    if (!html) {
      console.log(`  âŒ Could not load profile page`);
      return [];
    }

    const $ = cheerio.load(html);
    const userInfo = extractUserInfo(profileUrl);

    // Check if this is a SPA (Single Page Application)
    const bodyText = $('body').text().substring(0, 500);
    if (bodyText.includes('System.import') || bodyText.includes('vite-legacy-entry')) {
      console.log(`  âš ï¸  Detected SPA - content loaded dynamically via JavaScript`);
      console.log(`  ğŸ’¡ This site requires JavaScript to load posts. Consider:`);
      console.log(`     1. Check if the user has posts (visit the URL manually)`);
      console.log(`     2. The site may have moved or changed structure`);
      console.log(`     3. API endpoints may have changed`);
      return [];
    }

    // Use enhanced HTML parser
    const posts = extractPostsFromProfileHTML($, profileUrl);

    // Extract username from page
    const username = extractUsernameFromProfile($, profileUrl);
    console.log(`  ğŸ‘¤ Found user: ${username}`);

    // Add username to all posts
    posts.forEach(post => {
      post.username = username;
    });

    console.log(`  ğŸ“‹ Found ${posts.length} posts to download`);
    return posts;
  }

  extractPostId(postUrl) {
    const urlParts = postUrl.split('/');
    return urlParts[urlParts.length - 1] || 'unknown';
  }

  async downloadPost(post, postIndex, totalPosts) {
    console.log(`\nğŸ“„ [${postIndex + 1}/${totalPosts}] Processing post: ${post.id}`);
    console.log(`  ğŸ”— URL: ${post.url}`);

    const postDir = path.join(this.baseDir, post.username, post.id);

    // First, check if we should skip this post
    const quickCheck = await getDownloadStatus(postDir);
    if (quickCheck === 'completed') {
      // Do a quick check without API data first
      const initialCheck = await isPostAlreadyDownloaded(postDir, null);
      if (initialCheck.downloaded) {
        console.log(`  â­ï¸  Skipping: Post already downloaded and verified`);
        this.stats.postsSkipped++;
        return;
      }
    }

    console.log(`  ğŸ“ Creating directory: ${postDir}`);
    await fs.ensureDir(postDir);

    // Try browser HTML fetching first
    console.log(`  ğŸŒ Trying browser HTML fetch...`);
    const html = await fetchPage(post.url, (msg) => console.log(`  ${msg}`));

    if (html) {
      const $ = cheerio.load(html);

      // Save HTML content
      await saveHtmlContent(postDir, html);
      console.log(`  ğŸ’¾ Saved HTML content`);

      // Check if this is SPA content
      const bodyText = $('body').text();
      let images = [];

      if (bodyText.includes('System.import') || bodyText.includes('vite-legacy-entry')) {
        console.log(`  âš ï¸  Post page is a SPA - using browser to extract images from rendered content`);

        // Use Puppeteer to extract images from the rendered page
        images = await browserClient.extractImagesFromRenderedPost(post.url, (msg) => console.log(`    ${msg}`));
      } else {
        // Try enhanced HTML parser first, then fallback to original
        images = extractMediaFromPostHTML($, post.url);
        if (images.length === 0) {
          console.log(`  â„¹ï¸  Enhanced parser found no images, trying original parser...`);
          images = extractImagesFromHTML($);
        }
      }

      console.log(`  ğŸ–¼ï¸  Found ${images.length} images to download from HTML`);

      if (images.length > 0) {
        // Use concurrent downloader for better performance
        const downloadStats = await this.concurrentDownloader.downloadImages(
          images,
          postDir,
          (msg) => console.log(`    ${msg}`),
          (stats) => {
            this.stats.imagesDownloaded += stats.completed;
            this.stats.errors += stats.failed;
            console.log(`  ğŸ“Š Batch complete: ${stats.completed} downloaded, ${stats.skipped} skipped, ${stats.failed} failed`);
          }
        );

        this.stats.postsDownloaded++;
        console.log(`  âœ… Post ${post.id} completed - saved to ${postDir}`);
        return;
      }
    }

    // Fallback to API if HTML fetch failed or found no images
    console.log(`  âš ï¸  HTML fetch failed or found no images, trying API fallback...`);
    const postData = await fetchPostFromAPI(post, (msg) => console.log(`    ${msg}`));

    // If we have post data, do a thorough check including image verification
    if (postData) {
      const thoroughCheck = await isPostAlreadyDownloaded(postDir, postData);
      if (thoroughCheck.downloaded) {
        console.log(`  â­ï¸  Skipping: Post already fully downloaded with all ${extractImagesFromPostData(postData).length} images verified`);
        this.stats.postsSkipped++;
        return;
      } else if (thoroughCheck.missingImages && thoroughCheck.missingImages.length > 0) {
        console.log(`  ğŸ”„ Resuming: Missing ${thoroughCheck.missingImages.length} images - ${thoroughCheck.reason}`);
      }

      console.log(`  âœ… Got post data from API`);

      // Save post metadata as JSON
      await savePostMetadata(postDir, postData);
      console.log(`  ğŸ’¾ Saved post metadata`);

      // Extract and download images from API data using concurrent downloader
      const images = extractImagesFromPostData(postData);
      console.log(`  ğŸ–¼ï¸  Found ${images.length} images to download from API`);

      if (images.length > 0) {
        const downloadStats = await this.concurrentDownloader.downloadImages(
          images,
          postDir,
          (msg) => console.log(`    ${msg}`),
          (stats) => {
            this.stats.imagesDownloaded += stats.completed;
            this.stats.errors += stats.failed;
            console.log(`  ğŸ“Š Batch complete: ${stats.completed} downloaded, ${stats.skipped} skipped, ${stats.failed} failed`);
          }
        );

        // Verify all images were downloaded correctly after batch completion
        await this.verifyPostImages(postDir, images, post.id);
      }
    } else {
      console.log(`  âŒ Both HTML and API approaches failed for this post`);
    }

    this.stats.postsDownloaded++;
    console.log(`  âœ… Post ${post.id} completed - saved to ${postDir}`);
  }

  async processProfilesFile(filename) {
    try {
      console.log(`ğŸ“‚ Reading profiles from: ${filename}`);
      const profileUrls = await readProfilesFile(filename);

      console.log(`ğŸ“‹ Found ${profileUrls.length} profile URLs to process\n`);

      for (let i = 0; i < profileUrls.length; i++) {
        const profileUrl = profileUrls[i];
        console.log(`\nğŸ”„ [${i + 1}/${profileUrls.length}] Processing profile: ${profileUrl}`);
        
        try {
          const posts = await this.getProfilePosts(profileUrl);
          
          if (posts.length === 0) {
            console.log(`  âš ï¸  No posts found for this profile`);
            this.stats.profilesProcessed++;
            console.log(`  âœ… Profile completed`);
            continue;
          }

          for (let j = 0; j < posts.length; j++) {
            await this.downloadPost(posts[j], j, posts.length);
            
            // Show progress bar after each post
            const progress = ((j + 1) / posts.length * 100).toFixed(1);
            const completedBars = Math.floor((j + 1) / posts.length * 20);
            const remainingBars = 20 - completedBars;
            const progressBar = 'â–ˆ'.repeat(completedBars) + 'â–‘'.repeat(remainingBars);
            console.log(`  ğŸ“Š Progress: [${progressBar}] ${j + 1}/${posts.length} (${progress}%)`);
          }
          
          this.stats.profilesProcessed++;
          console.log(`  âœ… Profile completed`);
        } catch (error) {
          this.stats.errors++;
          console.error(`  âŒ Error processing profile: ${error.message}`);
          console.log(`  â­ï¸  Continuing with next profile...`);
        }
      }

      this.printSummary();
    } catch (error) {
      this.stats.errors++;
      console.error(`âŒ Error processing profiles file: ${error.message}`);
    }
  }

  async verifyPostImages(postDir, expectedImages, postId) {
    console.log(`  ğŸ” Verifying ${expectedImages.length} images for post ${postId}...`);
    
    try {
      const verification = await verifyAllImagesDownloaded(postDir, expectedImages);
      
      if (verification.allPresent) {
        console.log(`  âœ… Verification passed: All ${verification.presentCount}/${verification.totalExpected} images verified`);
      } else {
        console.log(`  âš ï¸  Verification issues found:`);
        console.log(`      ğŸ“Š Present: ${verification.presentCount}/${verification.totalExpected}`);
        
        if (verification.missingFiles.length > 0) {
          console.log(`      âŒ Missing files (${verification.missingFiles.length}):`);
          verification.missingFiles.slice(0, 5).forEach(file => {
            console.log(`         â€¢ ${file}`);
          });
          if (verification.missingFiles.length > 5) {
            console.log(`         ... and ${verification.missingFiles.length - 5} more`);
          }
        }
        
        if (verification.corruptedFiles.length > 0) {
          console.log(`      ğŸ”§ Corrupted files (${verification.corruptedFiles.length}):`);
          verification.corruptedFiles.slice(0, 5).forEach(file => {
            console.log(`         â€¢ ${file.name} (${file.reason})`);
          });
          if (verification.corruptedFiles.length > 5) {
            console.log(`         ... and ${verification.corruptedFiles.length - 5} more`);
          }
        }
        
        // Update stats to reflect verification issues
        this.stats.errors += verification.missingCount;
      }
    } catch (error) {
      console.log(`  âŒ Verification failed: ${error.message}`);
      this.stats.errors++;
    }
  }

  printSummary() {
    console.log('\n' + '='.repeat(50));
    console.log('ğŸ“Š DOWNLOAD SUMMARY');
    console.log('='.repeat(50));
    console.log(`âœ… Profiles processed: ${this.stats.profilesProcessed}`);
    console.log(`ğŸ“„ Posts downloaded: ${this.stats.postsDownloaded}`);
    console.log(`â­ï¸  Posts skipped: ${this.stats.postsSkipped}`);
    console.log(`ğŸ–¼ï¸  Images downloaded: ${this.stats.imagesDownloaded}`);
    console.log(`âŒ Errors encountered: ${this.stats.errors}`);
    console.log('='.repeat(50));
    
    if (this.stats.errors === 0) {
      console.log('ğŸ‰ All downloads completed successfully!');
    } else {
      console.log('âš ï¸  Some errors occurred during download. Check logs above.');
    }
  }
}

module.exports = KemonoDownloader;